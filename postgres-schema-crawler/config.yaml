# PostgreSQL Schema Crawler Configuration

database:
  host: localhost
  port: 5432
  name: temp1
  user: postgres
  password: Kingkong@1
  schema: public

# Crawler settings
crawler:
  # Include these object types in the crawl
  include_types:
    - BASE TABLE
    - VIEW
    - FOREIGN TABLE
  
  # Maximum number of tables to process (0 = unlimited)
  max_tables: 0
  
  # Whether to include constraint information
  include_constraints: true
  
  # Whether to include index information
  include_indexes: false
  
  # Table filtering options
  table_filter:
    # List of specific tables to include (empty = all tables)
    include_tables: ['employees']
    # List of tables to exclude (empty = no exclusions)
    exclude_tables: []
    # Pattern matching for table names (supports wildcards)
    include_patterns: []
    exclude_patterns: []
    # Case sensitive pattern matching
    case_sensitive: false

# Output settings
output:
  # Directory for storing metadata and reports
  data_dir: data
  
  # Format for schema exports (json, csv, markdown)
  export_format: json
  
  # Whether to create detailed reports
  create_reports: true

# Metadata settings
metadata:
  # Custom fields to track (can be extended)
  custom_fields:
    - description
    - owner
    - tags
    - business_owner
    - data_classification
  
  # File to store custom metadata annotations
  annotations_file: data/annotations.yaml 